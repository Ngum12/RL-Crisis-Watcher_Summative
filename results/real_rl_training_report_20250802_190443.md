# Real RL Training Results - Africa Crisis Response

**Generated**: 2025-08-02 19:06:39
**Environment**: Crisis Response (Cameroon, DR Congo, Sudan)
**Algorithms**: DQN, PPO, A2C
**Training Library**: Stable Baselines3

---

## Executive Summary

Trained real neural network agents on African crisis response scenarios.

**Best Performing Algorithm**: DQN (Mean Reward: 7066.43)

---

## Detailed Results

| Algorithm | Mean Reward | Std Reward | Lives Saved | Crises Prevented | Training Time (s) |
|-----------|-------------|------------|-------------|------------------|-------------------|
| DQN | 7066.43 | 66.00 | 118475 | 0 | 34 |
| PPO | 7047.88 | 99.26 | 119194 | 0 | 36 |
| A2C | 6178.39 | 63.49 | 250794 | 0 | 42 |

---

## Algorithm Analysis


### DQN

- **Mean Reward**: 7066.43 ± 66.00
- **Performance Range**: 6970.19 to 7183.43
- **Lives Saved**: 118475 (evaluation episodes)
- **Crises Prevented**: 0
- **Training Time**: 34 seconds


### PPO

- **Mean Reward**: 7047.88 ± 99.26
- **Performance Range**: 6906.51 to 7239.64
- **Lives Saved**: 119194 (evaluation episodes)
- **Crises Prevented**: 0
- **Training Time**: 36 seconds


### A2C

- **Mean Reward**: 6178.39 ± 63.49
- **Performance Range**: 6099.94 to 6312.35
- **Lives Saved**: 250794 (evaluation episodes)
- **Crises Prevented**: 0
- **Training Time**: 42 seconds


---

## Model Files

**Saved Models:**
- Best models: `models/{algorithm}_best/best_model.zip`
- Final models: `models/{algorithm}_final_20250802_190443.zip`
- Checkpoints: `models/{algorithm}_checkpoints/`

**Logs:**
- Training logs: `logs/training_20250802_190443.log`
- Evaluation logs: `logs/{algorithm}_eval/`
- Monitor logs: `logs/{algorithm}_monitor_*/`

---

## Usage

Load trained models:
```python
from stable_baselines3 import DQN, PPO, A2C

# Load best model
model = DQN.load("models/dqn_best/best_model")

# Evaluate on environment
env = CrisisResponseEnv()
obs, _ = env.reset()
action, _ = model.predict(obs)
```

---

*Report generated by Real RL Training System*
